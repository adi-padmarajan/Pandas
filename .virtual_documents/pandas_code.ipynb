





import pandas as pd


# Pandas -> Series, DataFrames
# Series -> 1-Dimensional labelled array
# DataFrame -> 2-Dimension Labelled array (Like a table)

info = {
    "Name": ["Gojo", "Toji", "Adi"],
    "Marks": [95, 78, 99]
}

df = pd.DataFrame(info)
print(df)

# The Dictionary Keys are the Headers of the DataFrame.
# 0, 1 and 2 are the labels in the DataFrame.


df


# Series - 1D Labelled Array
s = pd.Series([1, 2, 3, 4, 5])
print(s)
print(type(s))

# Index
print(s[0])
print(s[2])

# Index and labels are not the same. We can also have custom labels.


# Adding a custom label
s = pd.Series([22, 23, 24, 25, 26], index = ["Adi", "Gojo", "Toji", "Nanami", "Sukuna"])
print(s)

# Accessing values using labels
print(s["Adi"])
print(s["Gojo"])

# Printing all the labels 
print(s.index)





s1 = pd.Series([1, 2, 3, 4, 5])
s2 = pd.Series([10, 20, 30, 40, 50])

print(s1 + s2)

s1[0] = 100
changed_s1 = s1.drop(0)

print(s1)
print(changed_s1)


# DataFrame (2D Labelled Array)

info = {
    "Name": ["Adam", "Eve", "Bob"],
    "Age": [23, 24, 25],
    "GPA": [9.5, 8.6, 7.2]
}

df = pd.DataFrame(info)
print(df) 
print(df.index)


# Lists of Lists 
df = pd.DataFrame([["Adam", 23], ["Bob", 23], ["Eve", 23]], columns = ["Name", "Age"])
print(df)


# Using NumPy Arrays to Create a Frame

import numpy as np
np_arr = np.array([[1, 2, 3], [4, 5, 6]])

df = pd.DataFrame(np_arr, columns = ["A", "B", "C"])
print(df)


# Usage with CSV

df = pd.read_csv("employee_data.csv")
print(df, type(df))


# JSON Data

df = pd.read_json("employee_data.json")
print(df, type(df))





df = pd.read_json("employee_data.json")
print(df, type(df))


# Methods

df.head() # First 5 Rows
df.tail() # Last 5 Rows

df.sample() # Just a random row from the table

df.info() # Summary of the data

df.shape # Returns a tuple of rows and 

df.describe() # Gives detailed statistical summaries for numerical value tables

df.columns # All the columns in the table

df.nunique() # Gives unique rows
'''
ID            10
Name          10
Age           10
Department     4
Salary        10
dtype: int64
'''


df


# AQI Dataset 

df = pd.read_csv("globalAirQuality.csv")

df


df.head()


df.tail()


df.describe()


# Selecting Data

# Column-Wise Selection

# Single Column
df["city"]

# Multiple Columns
df[["city", "aqi"]]






# Getting the first row
df.loc[0]


df.loc[0:2] # Starting Index : Ending Index (inclusive)


# loc selects data by label
# iloc selects by integer position
df.loc[2]
df.iloc[0:2] # End index is exclusive


# Individual Cells
df.loc[0, "aqi"]
df.loc[0:2, ["country", "city", "latitude", "longitude"]] # Cannot use this for iloc as it requires a numeric index
# iloc version
# df.iloc[0:3, 1:5] 


# Select single scalar value - at & iat
df.at[0, "city"]
df.iat[0, 2]


# Filtering of Data

df[(df["aqi"] > 100) & (df["temperature"] > 30)]


df[ df["aqi"] > 100][["city", "aqi"]]


aqi_data = df[ df["aqi"] > 100][["city", "aqi"]]

aqi_data.iloc[0]  





# Query (Returns a copy and not a view)
df.query("aqi > 100 & temperature > 30")


# With Chaining
df.query("aqi > 100 & temperature > 30")[["city", "aqi"]]


# Using Variables 
aqi_value = 100
df.query("aqi > @aqi_value & temperature > 30")[["city", "aqi"]]





# Clean Data - Missing Values
# isnull() returns true wherever there is a null value 

df = pd.read_csv("raw_data.csv")
df.isnull()


# Count the number of missing values per column using chaining functions
df.isnull().sum()


# dropna() drops all the null values from the dataframe (removes the entire row)
df.dropna()

# To drop the column (Change the axis)
df.dropna(axis = 1)



# fillna(value) will fill all missing values
df.fillna(0) #Fill all missing values with 0

# To Fill a specific column with 0s
df["age"].fillna(0)

# Fill with mean values 
cleaned_data = df.copy()
age_mean = cleaned_data["age"].mean()
cleaned_data["age"] = df["age"].fillna(age_mean)

cleaned_data


# ffill() --> Forward Fill
df.ffill()


## bfill() --> Backward Fill
df.bfill()





# Handle Duplicates

# Check Duplicate Values
df.duplicated()

# Drop Duplicates 
df.drop_duplicates(inplace = True)
# inplace = True changes the value in the original data


df





# Data Types

df.dtypes  # Datatypes of the columns


# To change the data types

df2 = df.copy()

df2 = df2.fillna(0)
df2 = df2["age"].astype("int64").copy()
df2.dtypes


date_str = pd.Series("2026-12-31")
type(date_str.dtypes)
# To convert to Pandas to_datetime()
date_str = pd.Series([pd.to_datetime("2026-12-31")])
type(date_str.dtypes)








# apply()
# create a function and pass the function to apply

df2 = df.copy()
df2["tax"] = df2.apply("income").apply(
    lambda x: "20%" if x >= 50000 else "10%"
)
df2


# map() Function

# To convert Male => M, Female => F, Unknown => U

gender_map = {"Male": "M", "Female": "F", "Unknown": "U"}
df2["gender"] = df2["gender"].map(gender_map)


# assign()
df2.assign(new_income = df2["income"] * 1.1)


# replace(old, new)

df2["country"] = df2["country"].replace("USA", "US")
df2





# rename
df2.columns = ["Id", "Name", "Age", "Country", "Gender", "Income", "Tax"] # Capitalize
df2


df2.rename(columns = {
    "Income": "Salary"
})

# To rename a row, use index
df2.rename(index = {1: "First"})
